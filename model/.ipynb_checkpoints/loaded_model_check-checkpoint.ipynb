{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from flask import Flask, jsonify, request\n",
    "from tensorflow.python.keras.models import load_model\n",
    "import pickle\n",
    "from tensorflow.python.keras.models import model_from_json\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.python.keras.layers import LSTM\n",
    "from tensorflow.python.keras.layers import GRU, Input, Dense, Flatten, Dropout, BatchNormalization, Embedding\n",
    "from tensorflow.python.keras.models import Sequential, K\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "    gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1750)])\n",
    "if 'session' in locals() and session is not None:\n",
    "    print('Close interactive session')\n",
    "    session.close()\n",
    "\n",
    "# load model\n",
    "#model = pickle.load(open('model.pkl','rb'))\n",
    "model = load_model('new_model2same.h5')\n",
    "\n",
    "# data_path = ['data']\n",
    "# filepath = os.sep.join(data_path + ['result_nodup.csv'])     \n",
    "# result_nodup = pd.read_csv(filepath, sep=',', engine='python')\n",
    "# result_nodup = result_nodup.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "\n",
    "accepted_chars = 'abcdefghijklmnopqrstuvwxyzàáâãäåçèéêëìíîïñòóôõöøùúüýÿčńōŕřšūž-–'\n",
    "word_vec_length = 25 \n",
    "char_vec_length = 63\n",
    "output_labels = 2 \n",
    "char_to_int = dict((c, i) for i, c in enumerate(accepted_chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(accepted_chars))\n",
    "\n",
    "# Removes all non accepted characters\n",
    "def normalize(line):\n",
    "    return [c.lower() for c in line if c.lower() in accepted_chars]\n",
    "\n",
    "# Returns a list of n lists with n = word_vec_length\n",
    "def name_encoding(name):\n",
    "     # Encode input data to int, e.g. a->1, z->26\n",
    "    integer_encoded = [char_to_int[char] for i, char in enumerate(name) if i < word_vec_length]\n",
    "    \n",
    "    # Start one-hot-encoding\n",
    "    onehot_encoded = list()\n",
    "    \n",
    "    for value in integer_encoded:\n",
    "        # create a list of n zeros, where n is equal to the number of accepted characters\n",
    "        letter = [0 for _ in range(char_vec_length)]\n",
    "        letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "        \n",
    "    # Fill up list to the max length. Lists need do have equal length to be able to convert it into an array\n",
    "    for _ in range(word_vec_length - len(name)):\n",
    "        onehot_encoded.append([0 for _ in range(char_vec_length)])\n",
    "        \n",
    "    return onehot_encoded\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name or Surname: Aleknsar\n",
      "['Aleknsar']\n",
      "I am 53.300125 sure \"Aleknsar\" is a name\n"
     ]
    }
   ],
   "source": [
    "namecheck = [input(\"Name or Surname: \")]\n",
    "print(namecheck)\n",
    "test = np.asarray([np.asarray(name_encoding(normalize(name)))\n",
    "                   for name in namecheck]).astype(np.float32)\n",
    "pred = model.predict(np.asarray(test))\n",
    "predictoin = np.squeeze(pred * 100)\n",
    "temp = ''.join(namecheck)\n",
    "if predictoin > 50:\n",
    "    print(\"I am\", predictoin, \"sure\", '\"{}\"'.format(temp), \"is a name\")\n",
    "else:\n",
    "    print(\"I am\", (100 - predictoin), '\"{}\"'.format(temp), \"is a surname\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
